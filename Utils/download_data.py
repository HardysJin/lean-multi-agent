#!/usr/bin/env python3
"""
LEAN å¸‚åœºæ•°æ®ä¸‹è½½å·¥å…· - æ™ºèƒ½ç‰ˆ
- è‡ªåŠ¨æ£€æŸ¥å¹¶è¡¥å……ç¼ºå¤±æ•°æ®
- æ”¯æŒå¢é‡æ›´æ–°ï¼ˆæ™ºèƒ½åˆå¹¶æ–°æ—§æ•°æ®ï¼‰
- æ”¯æŒå¤šç§åˆ†è¾¨ç‡ï¼šdailyï¼ˆæ—¥çº¿ï¼‰ã€minuteï¼ˆåˆ†é’Ÿçº¿ï¼‰ã€hourï¼ˆå°æ—¶çº¿ï¼‰
- æ­£ç¡®çš„LEANæ ¼å¼ï¼ˆä»·æ ¼*10000ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # æ‰¹é‡ä¸‹è½½
    python3 download_data.py
    
    # åœ¨ä»£ç ä¸­ä½¿ç”¨
    from download_data import ensure_data_for_backtest
    ensure_data_for_backtest(['SPY'], '2024-01-01', '2025-03-31', resolution='daily')
"""

import yfinance as yf
import pandas as pd
import os
from datetime import datetime
import zipfile
from pathlib import Path
import time

# é»˜è®¤é…ç½®
DEFAULT_SYMBOLS = ['SPY', 'AAPL', 'NVDA', 'MSFT', 'GOOGL', 'TSLA']
DEFAULT_START = '2020-01-01'
DEFAULT_END = '2025-09-30'
DATA_DIR = './Lean/Data/equity/usa/daily'

# åˆ†è¾¨ç‡æ˜ å°„
RESOLUTION_MAP = {
    'daily': {
        'interval': '1d',
        'dir': 'daily',
        'time_format': '%Y%m%d 00:00',
        'split_by_day': False,  # æ—¥çº¿æ•°æ®ï¼šæ‰€æœ‰æ•°æ®åœ¨ä¸€ä¸ªæ–‡ä»¶
        'price_multiplier': 10000  # æ—¥çº¿ä»·æ ¼ä¹˜ä»¥10000
    },
    'hour': {
        'interval': '1h',
        'dir': 'hour',
        'time_format': '%Y%m%d %H:%M',
        'split_by_day': False,  # å°æ—¶æ•°æ®ï¼šæ‰€æœ‰æ•°æ®åœ¨ä¸€ä¸ªæ–‡ä»¶
        'price_multiplier': 10000
    },
    'minute': {
        'interval': '1m',
        'dir': 'minute',
        'time_format': '%Y%m%d %H:%M',
        'split_by_day': True,  # åˆ†é’Ÿæ•°æ®ï¼šæŒ‰å¤©åˆ†æ–‡ä»¶
        'price_multiplier': 10000  # åˆ†é’Ÿæ•°æ®ä»·æ ¼ä¹Ÿä¹˜ä»¥10000
    }
}

def get_data_dir_for_resolution(resolution='daily', symbol=None):
    """æ ¹æ®åˆ†è¾¨ç‡è·å–æ•°æ®ç›®å½•
    
    Args:
        resolution: åˆ†è¾¨ç‡ (daily, hour, minute)
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆåˆ†é’Ÿæ•°æ®éœ€è¦å•ç‹¬çš„æ–‡ä»¶å¤¹ï¼‰
    
    Returns:
        æ•°æ®ç›®å½•è·¯å¾„
    """
    base_dir = './Lean/Data/equity/usa'
    if resolution in RESOLUTION_MAP:
        res_dir = f"{base_dir}/{RESOLUTION_MAP[resolution]['dir']}"
        # åˆ†é’Ÿæ•°æ®éœ€è¦ä¸ºæ¯ä¸ªè‚¡ç¥¨åˆ›å»ºå•ç‹¬çš„æ–‡ä»¶å¤¹
        if resolution == 'minute' and symbol:
            return f"{res_dir}/{symbol.lower()}"
        return res_dir
    return f"{base_dir}/daily"

def check_existing_data(symbol, data_dir=DATA_DIR, resolution='daily'):
    """æ£€æŸ¥æœ¬åœ°å·²æœ‰æ•°æ®çš„æ—¥æœŸèŒƒå›´
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        data_dir: æ•°æ®ç›®å½•
        resolution: åˆ†è¾¨ç‡
    
    Returns:
        (start_date, end_date) æˆ– (None, None)
    """
    # ä½¿ç”¨æ­£ç¡®çš„ç›®å½•
    actual_dir = get_data_dir_for_resolution(resolution, symbol) if data_dir == DATA_DIR else data_dir
    
    # åˆ†é’Ÿæ•°æ®æŒ‰å¤©åˆ†æ–‡ä»¶ï¼Œéœ€è¦æ£€æŸ¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    if resolution == 'minute':
        if not Path(actual_dir).exists():
            return None, None
        
        try:
            # è·å–æ‰€æœ‰ YYYYMMDD_trade.zip æ–‡ä»¶
            trade_files = sorted([f for f in os.listdir(actual_dir) if f.endswith('_trade.zip')])
            
            if not trade_files:
                return None, None
            
            # ä»æ–‡ä»¶åè§£ææ—¥æœŸ
            first_date = datetime.strptime(trade_files[0][:8], '%Y%m%d')
            last_date = datetime.strptime(trade_files[-1][:8], '%Y%m%d')
            
            return first_date, last_date
        except Exception:
            return None, None
    
    # æ—¥çº¿å’Œå°æ—¶æ•°æ®ï¼šå•ä¸ª zip æ–‡ä»¶
    else:
        zip_path = Path(actual_dir) / f"{symbol.lower()}.zip"
        
        if not zip_path.exists():
            return None, None
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zf:
                csv_name = f"{symbol.lower()}.csv"
                if csv_name not in zf.namelist():
                    return None, None
                
                content = zf.read(csv_name).decode('utf-8')
                lines = content.strip().split('\n')
                
                if len(lines) < 2:
                    return None, None
                
                # è§£æç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œçš„æ—¥æœŸ
                first_date = datetime.strptime(lines[0].split(',')[0], '%Y%m%d %H:%M')
                last_date = datetime.strptime(lines[-1].split(',')[0], '%Y%m%d %H:%M')
                
                return first_date, last_date
        except Exception:
            return None, None

def _download_minute_data_in_batches(ticker, start_date, end_date, interval):
    """åˆ†æ‰¹ä¸‹è½½åˆ†é’Ÿæ•°æ®ï¼ˆç»•è¿‡ Yahoo Finance 8å¤©é™åˆ¶ï¼‰
    
    Yahoo Finance API é™åˆ¶ï¼š1åˆ†é’Ÿæ•°æ®æ¯æ¬¡è¯·æ±‚æœ€å¤š8å¤©
    
    Args:
        ticker: yfinance Ticker å¯¹è±¡
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå­—ç¬¦ä¸²æˆ–datetimeï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå­—ç¬¦ä¸²æˆ–datetimeï¼‰
        interval: æ•°æ®é—´éš” (å¦‚ '1m')
    
    Returns:
        åˆå¹¶åçš„ DataFrame
    """
    from datetime import datetime, timedelta
    
    # è½¬æ¢ä¸º datetime
    if isinstance(start_date, str):
        start_dt = pd.to_datetime(start_date)
    else:
        start_dt = start_date if isinstance(start_date, datetime) else pd.to_datetime(start_date)
    
    if isinstance(end_date, str):
        end_dt = pd.to_datetime(end_date)
    else:
        end_dt = end_date if isinstance(end_date, datetime) else pd.to_datetime(end_date)
    
    # è®¡ç®—æ€»å¤©æ•°
    total_days = (end_dt - start_dt).days
    
    # å¦‚æœå°äºç­‰äº7å¤©ï¼Œç›´æ¥ä¸‹è½½
    if total_days <= 7:
        print(f"   æ—¶é—´èŒƒå›´: {total_days} å¤©ï¼Œç›´æ¥ä¸‹è½½")
        return ticker.history(start=start_dt, end=end_dt, interval=interval)
    
    # åˆ†æ‰¹ä¸‹è½½ï¼ˆæ¯æ‰¹7å¤©ï¼‰
    batch_size = 7
    batches = []
    current_start = start_dt
    batch_num = 0
    
    print(f"   æ—¶é—´èŒƒå›´: {total_days} å¤©ï¼Œå°†åˆ† {(total_days // batch_size) + 1} æ‰¹ä¸‹è½½")
    
    while current_start < end_dt:
        batch_num += 1
        current_end = min(current_start + timedelta(days=batch_size), end_dt)
        
        print(f"   æ‰¹æ¬¡ {batch_num}: {current_start.strftime('%Y-%m-%d')} åˆ° {current_end.strftime('%Y-%m-%d')}", end=' ')
        
        try:
            batch_df = ticker.history(start=current_start, end=current_end, interval=interval)
            
            if not batch_df.empty:
                batches.append(batch_df)
                print(f"âœ“ ({len(batch_df)} æ¡)")
            else:
                print("âš ï¸ æ— æ•°æ®")
                
            # é¿å…è§¦å‘é¢‘ç‡é™åˆ¶
            time.sleep(0.5)
            
        except Exception as e:
            print(f"âœ— é”™è¯¯: {e}")
        
        current_start = current_end
    
    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    if not batches:
        print("âŒ æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®")
        return pd.DataFrame()
    
    print(f"   åˆå¹¶ {len(batches)} ä¸ªæ‰¹æ¬¡çš„æ•°æ®...")
    merged_df = pd.concat(batches)
    
    # å»é‡ï¼ˆå¯èƒ½æœ‰é‡å ï¼‰
    merged_df = merged_df[~merged_df.index.duplicated(keep='first')]
    
    # æ’åº
    merged_df = merged_df.sort_index()
    
    return merged_df

def _save_minute_data_by_day(df, symbol, data_dir, res_config):
    """ä¿å­˜åˆ†é’Ÿæ•°æ®ï¼ˆæŒ‰å¤©åˆ†æ–‡ä»¶ï¼ŒLEAN å®˜æ–¹æ ¼å¼ï¼‰
    
    æ ¼å¼ï¼šequity/usa/minute/{symbol}/YYYYMMDD_trade.zip
    æ–‡ä»¶å†…å®¹ï¼šYYYYMMDD_symbol_minute_trade.csv  
    ä»·æ ¼æ ¼å¼ï¼šæ•´æ•°ï¼ˆä»·æ ¼ Ã— 10000ï¼‰- LEANæ ‡å‡†æ ¼å¼
    
    Args:
        df: DataFrame with minute data
        symbol: Stock symbol
        data_dir: Directory to save files
        res_config: Resolution configuration
    
    Returns:
        Number of days saved
    """
    multiplier = res_config['price_multiplier']
    
    # æŒ‰æ—¥æœŸåˆ†ç»„
    df_grouped = df.groupby(df.index.date)
    saved_count = 0
    
    for date, day_data in df_grouped:
        date_str = date.strftime('%Y%m%d')
        
        # æ–‡ä»¶åï¼šYYYYMMDD_trade.zip
        zip_filename = f"{date_str}_trade.zip"
        zip_path = Path(data_dir) / zip_filename
        
        # CSV æ–‡ä»¶åï¼šYYYYMMDD_symbol_minute_trade.csv
        csv_filename = f"{date_str}_{symbol.lower()}_minute_trade.csv"
        
        # è½¬æ¢ä¸º LEAN æ ¼å¼ï¼ˆæ—¶é—´=æ¯«ç§’æ•°ï¼Œä»·æ ¼=æ•´æ•°Ã—10000ï¼‰
        lean_data = []
        for timestamp, row in day_data.iterrows():
            # LEANåˆ†é’Ÿæ•°æ®ä½¿ç”¨"ä»åˆå¤œå¼€å§‹çš„æ¯«ç§’æ•°"ä½œä¸ºæ—¶é—´æˆ³
            milliseconds = (timestamp.hour * 3600 + timestamp.minute * 60 + timestamp.second) * 1000
            open_price = int(row['Open'] * multiplier)
            high_price = int(row['High'] * multiplier)
            low_price = int(row['Low'] * multiplier)
            close_price = int(row['Close'] * multiplier)
            volume = int(row['Volume'])
            lean_data.append(f"{milliseconds},{open_price},{high_price},{low_price},{close_price},{volume}")
        
        # ä¿å­˜åˆ° zip æ–‡ä»¶
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.writestr(csv_filename, '\n'.join(lean_data))
        
        saved_count += 1
    
    return saved_count

def _save_consolidated_data(df, symbol, data_dir, res_config, existing_start, existing_end):
    """ä¿å­˜æ—¥çº¿/å°æ—¶æ•°æ®ï¼ˆå•ä¸ªæ–‡ä»¶ï¼‰
    
    æ ¼å¼ï¼šequity/usa/{resolution}/{symbol}.zip
    ä»·æ ¼æ ¼å¼ï¼šæ•´æ•°ï¼ˆä¹˜ä»¥10000ï¼‰
    
    Args:
        df: DataFrame with data
        symbol: Stock symbol
        data_dir: Directory to save file
        res_config: Resolution configuration
        existing_start: Existing data start date (for merging)
        existing_end: Existing data end date (for merging)
    """
    multiplier = res_config['price_multiplier']
    
    # å¦‚æœæœ‰å·²æœ‰æ•°æ®ï¼Œåˆå¹¶
    if existing_start and existing_end:
        print(f"ğŸ”„ åˆå¹¶æ–°æ—§æ•°æ®...")
        zip_path = Path(data_dir) / f"{symbol.lower()}.zip"
        
        with zipfile.ZipFile(zip_path, 'r') as zf:
            content = zf.read(f"{symbol.lower()}.csv").decode('utf-8')
            lines = content.strip().split('\n')
            
            # è§£ææ—§æ•°æ®åˆ°å­—å…¸
            old_data = {}
            for line in lines:
                parts = line.split(',')
                timestamp_str = parts[0]
                old_data[timestamp_str] = line
            
            # æ·»åŠ æ–°æ•°æ®ï¼ˆæ–°æ•°æ®ä¼˜å…ˆï¼‰
            for date, row in df.iterrows():
                date_str = date.strftime(res_config['time_format'])
                open_price = int(row['Open'] * multiplier)
                high_price = int(row['High'] * multiplier)
                low_price = int(row['Low'] * multiplier)
                close_price = int(row['Close'] * multiplier)
                volume = int(row['Volume'])
                old_data[date_str] = f"{date_str},{open_price},{high_price},{low_price},{close_price},{volume}"
            
            # æŒ‰æ—¶é—´æˆ³æ’åº
            sorted_timestamps = sorted(old_data.keys())
            lean_data = [old_data[ts] for ts in sorted_timestamps]
    else:
        # è½¬æ¢ä¸º LEAN æ ¼å¼
        lean_data = []
        for date, row in df.iterrows():
            date_str = date.strftime(res_config['time_format'])
            open_price = int(row['Open'] * multiplier)
            high_price = int(row['High'] * multiplier)
            low_price = int(row['Low'] * multiplier)
            close_price = int(row['Close'] * multiplier)
            volume = int(row['Volume'])
            lean_data.append(f"{date_str},{open_price},{high_price},{low_price},{close_price},{volume}")
    
    # ä¿å­˜åˆ° zip æ–‡ä»¶
    zip_path = Path(data_dir) / f"{symbol.lower()}.zip"
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(f"{symbol.lower()}.csv", '\n'.join(lean_data))

def download_and_convert(symbol, start_date, end_date, data_dir=DATA_DIR, resolution='daily'):
    """ä¸‹è½½å¹¶è½¬æ¢å•ä¸ªè‚¡ç¥¨æ•°æ®ï¼ˆæ™ºèƒ½å¢é‡æ›´æ–°ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        data_dir: æ•°æ®ç›®å½•ï¼ˆå¦‚æœæ˜¯é»˜è®¤å€¼ï¼Œä¼šè‡ªåŠ¨æ ¹æ®resolutionè°ƒæ•´ï¼‰
        resolution: åˆ†è¾¨ç‡ ('daily', 'hour', 'minute')
    """
    # è·å–åˆ†è¾¨ç‡é…ç½®
    res_config = RESOLUTION_MAP.get(resolution, RESOLUTION_MAP['daily'])
    
    # ä½¿ç”¨æ­£ç¡®çš„ç›®å½•
    actual_dir = get_data_dir_for_resolution(resolution, symbol) if data_dir == DATA_DIR else data_dir
    
    print(f"\n{'='*60}")
    print(f"ä¸‹è½½ {symbol} æ•°æ® ({resolution})...")
    print(f"{'='*60}")
    
    # æ£€æŸ¥å·²æœ‰æ•°æ®
    existing_start, existing_end = check_existing_data(symbol, data_dir, resolution)
    
    if existing_start and existing_end:
        print(f"ğŸ“ æœ¬åœ°æ•°æ®: {existing_start.strftime('%Y-%m-%d')} åˆ° {existing_end.strftime('%Y-%m-%d')}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°
        req_start = pd.to_datetime(start_date)
        req_end = pd.to_datetime(end_date)
        
        if existing_start <= req_start and existing_end >= req_end:
            print(f"âœ… {symbol}: æ•°æ®å……è¶³ï¼Œæ— éœ€ä¸‹è½½")
            return True
        else:
            print(f"ğŸ“¥ éœ€è¦è¡¥å……æ•°æ®...")
    
    try:
        # ä¸‹è½½æ•°æ®
        print(f"ğŸ“¥ ä» Yahoo Finance ä¸‹è½½ {symbol} ({resolution})...")
        print(f"   æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"   æ•°æ®é—´éš”: {res_config['interval']}")
        
        ticker = yf.Ticker(symbol)
        
        # æ ¹æ®åˆ†è¾¨ç‡ä¸‹è½½å¯¹åº”æ•°æ®
        # æ³¨æ„ï¼šYahoo Finance å¯¹åˆ†é’Ÿæ•°æ®æœ‰æ—¶é—´é™åˆ¶ï¼ˆæ¯æ¬¡è¯·æ±‚æœ€å¤š8å¤©ï¼‰
        if resolution == 'minute':
            print(f"âš ï¸  æ³¨æ„ï¼šYahoo Finance åˆ†é’Ÿæ•°æ®é™åˆ¶æ¯æ¬¡è¯·æ±‚8å¤©")
            # åˆ†æ‰¹ä¸‹è½½
            df = _download_minute_data_in_batches(ticker, start_date, end_date, res_config['interval'])
        else:
            df = ticker.history(start=start_date, end=end_date, interval=res_config['interval'])
        
        if df.empty:
            print(f"âŒ {symbol}: æœªè·å–åˆ°æ•°æ®")
            if resolution == 'minute':
                print(f"   å¯èƒ½åŸå› :")
                print(f"   1. Yahoo Finance å¯¹åˆ†é’Ÿæ•°æ®æœ‰æ—¶é—´é™åˆ¶")
                print(f"   2. è‚¡ç¥¨ä»£ç ä¸å­˜åœ¨æˆ–å·²é€€å¸‚")
                print(f"   3. æ—¶é—´èŒƒå›´è¶…å‡ºå¯ç”¨èŒƒå›´")
                print(f"   å»ºè®®: å°è¯•ç¼©çŸ­æ—¶é—´èŒƒå›´ï¼ˆä¾‹å¦‚æœ€è¿‘30å¤©ï¼‰")
            return False
        
        data_type = 'æ¡' if resolution in ['minute', 'hour'] else 'å¤©'
        print(f"âœ… è·å–åˆ° {len(df)} {data_type}çš„æ•°æ®")
        print(f"   æ—¥æœŸ: {df.index[0].strftime('%Y-%m-%d %H:%M')} åˆ° {df.index[-1].strftime('%Y-%m-%d %H:%M')}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(actual_dir, exist_ok=True)
        
        # æ ¹æ®åˆ†è¾¨ç‡ä½¿ç”¨ä¸åŒçš„ä¿å­˜æ ¼å¼
        if res_config['split_by_day']:
            # åˆ†é’Ÿæ•°æ®ï¼šæŒ‰å¤©åˆ†æ–‡ä»¶ä¿å­˜
            print(f"ğŸ“ æŒ‰å¤©åˆ†æ–‡ä»¶ä¿å­˜åˆ°: {actual_dir}/")
            saved_count = _save_minute_data_by_day(df, symbol, actual_dir, res_config)
            print(f"ğŸ’¾ ä¿å­˜å®Œæˆ: {saved_count} ä¸ªäº¤æ˜“æ—¥")
        else:
            # æ—¥çº¿/å°æ—¶æ•°æ®ï¼šå•ä¸ªæ–‡ä»¶ä¿å­˜
            _save_consolidated_data(df, symbol, actual_dir, res_config, existing_start, existing_end)
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {actual_dir}/{symbol.lower()}.zip")
            print(f"   æ€»å…± {len(df)} {data_type}çš„æ•°æ®")
        
        return True
        
    except Exception as e:
        print(f"âŒ {symbol}: ä¸‹è½½å¤±è´¥")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        
        # æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºå»ºè®®
        error_msg = str(e).lower()
        if 'no data found' in error_msg or 'empty' in error_msg:
            print(f"\n   å¯èƒ½åŸå› :")
            print(f"   - è‚¡ç¥¨ä»£ç ä¸å­˜åœ¨æˆ–æ‹¼å†™é”™è¯¯")
            print(f"   - è¯¥è‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰äº¤æ˜“æ•°æ®")
            if resolution == 'minute':
                print(f"   - åˆ†é’Ÿæ•°æ®çš„æ—¶é—´èŒƒå›´è¶…å‡ºé™åˆ¶ï¼ˆYahoo Finance é€šå¸¸åªæä¾›æœ€è¿‘7-60å¤©ï¼‰")
        elif 'connection' in error_msg or 'timeout' in error_msg:
            print(f"\n   å¯èƒ½åŸå› :")
            print(f"   - ç½‘ç»œè¿æ¥é—®é¢˜")
            print(f"   - Yahoo Finance æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
        
        print(f"\n   è¯¦ç»†é”™è¯¯è¿½è¸ª:")
        import traceback
        traceback.print_exc()
        
        return False

def ensure_data_for_backtest(symbols, start_date, end_date, data_dir=DATA_DIR, resolution='daily'):
    """
    ä¸ºå›æµ‹å‡†å¤‡æ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰è‚¡ç¥¨æ•°æ®å……è¶³
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
        data_dir: æ•°æ®ç›®å½•
        resolution: åˆ†è¾¨ç‡ ('daily', 'hour', 'minute')
        
    Returns:
        bool: æ˜¯å¦æ‰€æœ‰æ•°æ®éƒ½å‡†å¤‡å®Œæˆ
    """
    print("="*70)
    print(f"LEAN æ•°æ®è‡ªåŠ¨å‡†å¤‡ ({resolution})")
    print("="*70)
    print(f"è‚¡ç¥¨: {', '.join(symbols)}")
    print(f"æ—¥æœŸ: {start_date} åˆ° {end_date}")
    print(f"åˆ†è¾¨ç‡: {resolution}")
    print("="*70)
    
    all_ready = True
    for symbol in symbols:
        if not download_and_convert(symbol, start_date, end_date, data_dir, resolution):
            all_ready = False
    
    print(f"\n{'='*70}")
    if all_ready:
        print("âœ… æ‰€æœ‰æ•°æ®å‡†å¤‡å®Œæˆ")
    else:
        print("âŒ éƒ¨åˆ†æ•°æ®å‡†å¤‡å¤±è´¥")
    print("="*70)
    
    return all_ready

def main():
    """ä¸»å‡½æ•° - æ‰¹é‡ä¸‹è½½é»˜è®¤è‚¡ç¥¨"""
    print("="*60)
    print("LEAN å¸‚åœºæ•°æ®ä¸‹è½½å·¥å…·")
    print("="*60)
    print(f"è‚¡ç¥¨åˆ—è¡¨: {', '.join(DEFAULT_SYMBOLS)}")
    print(f"æ—¥æœŸèŒƒå›´: {DEFAULT_START} åˆ° {DEFAULT_END}")
    print(f"æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"æ•°æ®ç±»å‹: ä»…æ—¥çº¿æ•°æ®")
    print("="*60)
    
    # æ£€æŸ¥yfinanceæ˜¯å¦å®‰è£…
    try:
        import yfinance
        print("\nâœ… yfinance å·²å®‰è£…")
    except ImportError:
        print("\nâŒ éœ€è¦å®‰è£… yfinance")
        print("   è¿è¡Œ: pip install yfinance pandas")
        return
    
    # ä¸‹è½½æ¯ä¸ªè‚¡ç¥¨çš„æ•°æ®
    success_count = 0
    for symbol in DEFAULT_SYMBOLS:
        if download_and_convert(symbol, DEFAULT_START, DEFAULT_END):
            success_count += 1
    
    print(f"\n{'='*60}")
    print(f"ä¸‹è½½å®Œæˆï¼")
    print(f"æˆåŠŸ: {success_count}/{len(DEFAULT_SYMBOLS)}")
    print(f"{'='*60}")
    
    if success_count == len(DEFAULT_SYMBOLS):
        print("\nâœ… æ‰€æœ‰æ•°æ®ä¸‹è½½æˆåŠŸ")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†è‚¡ç¥¨ä¸‹è½½å¤±è´¥")

if __name__ == '__main__':
    main()
